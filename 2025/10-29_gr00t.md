# GR00T N1

* Authors: NVIDIA
* Link: https://arxiv.org/pdf/2503.14734
* Date: 2025-03-27

## Notes

* Vision-Language-Action (VLA) model, vision-language (system 2, 10Hz), diffusion transformer (system 1, 120Hz).
* Data pyramid: real-world robotic data, synthetic robotic data, web data & human videos.
* GR00T-N1-2B model has 2.2B parameters in total, with 1.34B in the VLM.
* The inference time for sampling a chunk of 16 actions is 63.9ms on an L40 GPU using bf16.
* Needs ground truth action chunks.
* Generate latent actions on human egocentric videos.
* Neural trajectories: use image-to-video generation models to generate counterfactual scenarios.
* Simulation trajectories: start with human demonstrations, generate training data in simulation.

## Ideas

* Needs a data flywheel.